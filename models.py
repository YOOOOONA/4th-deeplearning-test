# -*- coding: utf-8 -*-
"""models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l7LNMg6sflSGw-jiz-gXtpN8icDQJk63
"""

from keras.models import Sequential
from keras.layers import MaxPooling2D
from keras.layers import Conv2D
from keras.layers import Activation, Dropout,Flatten,Dense
from sklearn.model_selection import train_test_split
import numpy as np
import os

def models(nb_classes):
  X_train,X_test,y_train,y_test== np.load("./datasets.npy")
  X_train=X_train.astype("float")/256
  X_test=X_test.astype("float")/256
  print('X_train shape:',X_train.shape)

  model=Sequential()
  model.add(Conv2D(32,(3,3), input_shape=X_train.shape[1:],padding='same'))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(Dropout(0.25))

  model.add(Conv2D(64, (3, 3), padding='same'))
  model.add(Activation('relu'))

  model.add(Conv2D(64, (3, 3)))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.25))

  # 전결합층
  model.add(Flatten())    # 벡터형태로 reshape
  model.add(Dense(512))   # 출력
  model.add(Activation('relu'))
  model.add(Dropout(0.5))

  model.add(Dense(nb_classes))
  model.add(Activation('softmax'))
  # 모델 구축하기
  model.compile(loss='binary_crossentropy',   # 최적화 함수 지정
      optimizer='rmsprop',
      metrics=['accuracy'])
  # 모델 확인
  print(model.summary())

  # 모델 훈련하기&학습 완료 모델 저장
  hdf5_file=model.fit(X_train, y_train, batch_size=32, nb_epoch=20)




  if os.path.exists(hdf5_file):
      # 기존에 학습된 모델 불러들이기
      model.load_weights(hdf5_file)
  else:
      # 학습한 모델이 없으면 파일로 저장
      model.fit(X_train, y_train, batch_size=32, nb_epoch=10)
      mymodel.pth=model.save_weights(hdf5_file)

def scoring(X_test,y_test):
  score = model.evaluate(X_test, y_test)
  print('loss=', score[0])        # loss
  print('accuracy=', score[1])    # acc